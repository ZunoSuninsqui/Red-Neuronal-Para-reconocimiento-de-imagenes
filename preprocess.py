"""Image preprocessing pipeline shared between training and inference."""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Tuple

import numpy as np
from PIL import Image, ImageFilter
import torch

TARGET_SIZE = 28
BACKGROUND_THRESHOLD = 0.5
FOREGROUND_THRESHOLD = 0.1


@dataclass
class PreprocessResult:
    """Stores the artefacts generated by the preprocessing pipeline."""

    image: Image.Image
    tensor: torch.Tensor


def load_image(path: Path | str) -> Image.Image:
    """Load an image from disk and convert it to grayscale."""

    image = Image.open(path)
    if image.mode != "L":
        image = image.convert("L")
    return image


def _normalize(arr: np.ndarray) -> np.ndarray:
    arr = arr.astype(np.float32) / 255.0
    if arr.mean() > BACKGROUND_THRESHOLD:
        arr = 1.0 - arr
    vmax = arr.max()
    vmin = arr.min()
    if vmax > vmin:
        arr = (arr - vmin) / (vmax - vmin)
    return arr


def _extract_foreground(arr: np.ndarray) -> np.ndarray:
    mask = arr > FOREGROUND_THRESHOLD
    if not mask.any():
        return arr
    coords = np.argwhere(mask)
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0) + 1
    cropped = arr[y0:y1, x0:x1]
    size = int(max(cropped.shape))
    square = np.zeros((size, size), dtype=np.float32)
    y_offset = (size - cropped.shape[0]) // 2
    x_offset = (size - cropped.shape[1]) // 2
    square[y_offset : y_offset + cropped.shape[0], x_offset : x_offset + cropped.shape[1]] = cropped
    return square


def _resize_and_pad(arr: np.ndarray, size: int = TARGET_SIZE) -> Image.Image:
    pil_image = Image.fromarray((arr * 255).astype(np.uint8))
    pil_image = pil_image.resize((size, size), Image.BILINEAR)
    return pil_image


def preprocess_image(image: Image.Image, apply_smoothing: bool = True) -> Image.Image:
    """Apply the preprocessing pipeline and return a 28×28 PIL image."""

    if image.mode != "L":
        image = image.convert("L")
    arr = np.asarray(image)
    arr = _normalize(arr)
    arr = _extract_foreground(arr)
    processed = _resize_and_pad(arr)
    if apply_smoothing:
        processed = processed.filter(ImageFilter.MaxFilter(3)).filter(ImageFilter.MinFilter(3))
    return processed


def image_to_tensor(image: Image.Image) -> torch.Tensor:
    """Convert a 28×28 PIL image to a normalised tensor."""

    arr = np.asarray(image, dtype=np.float32) / 255.0
    tensor = torch.from_numpy(arr).unsqueeze(0)
    return tensor


def prepare_tensor(path_or_image: Path | str | Image.Image) -> torch.Tensor:
    """Load and preprocess an image returning a tensor."""

    if isinstance(path_or_image, (str, Path)):
        image = load_image(path_or_image)
    else:
        image = path_or_image
    processed = preprocess_image(image)
    return image_to_tensor(processed)


def run_pipeline(path_or_image: Path | str | Image.Image) -> PreprocessResult:
    """Convenience helper returning both PIL image and tensor."""

    if isinstance(path_or_image, (str, Path)):
        image = load_image(path_or_image)
    else:
        image = path_or_image
    processed = preprocess_image(image)
    tensor = image_to_tensor(processed)
    return PreprocessResult(image=processed, tensor=tensor)
